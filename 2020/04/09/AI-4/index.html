<!-- build time:Sun Oct 24 2021 15:00:13 GMT+0800 (台北標準時間) --><!DOCTYPE html><html lang="zh-TW"><head><meta charset="UTF-8"><meta name="viewport" content="width=device-width,initial-scale=1,maximum-scale=2"><meta name="theme-color" content="#FFF"><link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon.png"><link rel="icon" type="image/ico" sizes="32x32" href="/images/favicon.ico"><meta http-equiv="Cache-Control" content="no-transform"><meta http-equiv="Cache-Control" content="no-siteapp"><link rel="alternate" type="application/rss+xml" title="永不停歇" href="https://zrn-code.github.io/rss.xml"><link rel="alternate" type="application/atom+xml" title="永不停歇" href="https://zrn-code.github.io/atom.xml"><link rel="alternate" type="application/json" title="永不停歇" href="https://zrn-code.github.io/feed.json"><script src="//code.tidio.co/xwpoo3nkpkhs9n7qnbgoxgfroyidjvjl.js" async></script><link rel="stylesheet" href="//fonts.googleapis.com/css?family=Mulish:300,300italic,400,400italic,700,700italic%7CFredericka%20the%20Great:300,300italic,400,400italic,700,700italic%7CNoto%20Serif%20JP:300,300italic,400,400italic,700,700italic%7CNoto%20Serif%20SC:300,300italic,400,400italic,700,700italic%7CInconsolata:300,300italic,400,400italic,700,700italic&display=swap&subset=latin,latin-ext"><link rel="stylesheet" href="/css/app.css?v=0.2.5"><meta name="keywords" content="AI,深度學習,實作AI,python,手寫辨識,keras"><link rel="canonical" href="https://zrn-code.github.io/2020/04/09/AI-4/"><title>第 04 篇、Keras MLP 辨識手寫數字 - 深度學習 AI - 寫很爛系列 | Zrn Code = 永不停歇 = 學習歷程</title><meta name="generator" content="Hexo 5.2.0"></head><body itemscope itemtype="http://schema.org/WebPage"><div id="loading"><div class="cat"><div class="body"></div><div class="head"><div class="face"></div></div><div class="foot"><div class="tummy-end"></div><div class="bottom"></div><div class="legs left"></div><div class="legs right"></div></div><div class="paw"><div class="hands left"></div><div class="hands right"></div></div></div></div><div id="container"><header id="header" itemscope itemtype="http://schema.org/WPHeader"><div class="inner"><div id="brand"><div class="pjax"><h1 itemprop="name headline">第 04 篇、Keras MLP 辨識手寫數字</h1><div class="meta"><span class="item" title="創建時間：2020-04-09 13:27:08"><span class="icon"><i class="ic i-calendar"></i> </span><span class="text">發表於</span> <time itemprop="dateCreated datePublished" datetime="2020-04-09T13:27:08+08:00">2020-04-09</time> </span><span class="item" title="文章字數"><span class="icon"><i class="ic i-pen"></i> </span><span class="text">文章字數</span> <span>4.9k</span> <span class="text">字</span> </span><span class="item" title="所需閱讀時間"><span class="icon"><i class="ic i-clock"></i> </span><span class="text">所需閱讀時間</span> <span>4 分鐘</span></span></div></div></div><nav id="nav"><div class="inner"><div class="toggle"><div class="lines" aria-label="切換導航欄"><span class="line"></span> <span class="line"></span> <span class="line"></span></div></div><ul class="menu"><li class="item title"><a href="/" rel="start">Zrn Code</a></li></ul><ul class="right"><li class="item theme"><i class="ic i-sun"></i></li><li class="item search"><i class="ic i-search"></i></li></ul></div></nav></div><div id="imgs" class="pjax"><ul><li class="item" data-background-image="https://tva2.sinaimg.cn/large/6833939bly1gicljitigmj20zk0m87fp.jpg"></li><li class="item" data-background-image="https://tva2.sinaimg.cn/large/6833939bly1gicm0fdw5cj20zk0m8hdt.jpg"></li><li class="item" data-background-image="https://tva2.sinaimg.cn/large/6833939bly1giclxp31goj20zk0m8qv5.jpg"></li><li class="item" data-background-image="https://tva2.sinaimg.cn/large/6833939bly1gipexw3o58j20zk0m8e81.jpg"></li><li class="item" data-background-image="https://tva2.sinaimg.cn/large/6833939bly1gicit31ffoj20zk0m8naf.jpg"></li><li class="item" data-background-image="https://tva2.sinaimg.cn/large/6833939bly1gicli3sbvtj20zk0m8x6p.jpg"></li></ul></div></header><div id="waves"><svg class="waves" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" viewBox="0 24 150 28" preserveAspectRatio="none" shape-rendering="auto"><defs><path id="gentle-wave" d="M-160 44c30 0 58-18 88-18s 58 18 88 18 58-18 88-18 58 18 88 18 v44h-352z"/></defs><g class="parallax"><use xlink:href="#gentle-wave" x="48" y="0"/><use xlink:href="#gentle-wave" x="48" y="3"/><use xlink:href="#gentle-wave" x="48" y="5"/><use xlink:href="#gentle-wave" x="48" y="7"/></g></svg></div><main><div class="inner"><div id="main" class="pjax"><div class="article wrap"><div class="breadcrumb" itemscope itemtype="https://schema.org/BreadcrumbList"><i class="ic i-home"></i> <span><a href="/">首頁</a></span><i class="ic i-angle-right"></i> <span itemprop="itemListElement" itemscope itemtype="https://schema.org/ListItem"><a href="/categories/%E5%AF%AB%E5%BE%88%E7%88%9B%E7%B3%BB%E5%88%97/" itemprop="item" rel="index" title="分類於 寫很爛系列"><span itemprop="name">寫很爛系列</span></a><meta itemprop="position" content="1"></span><i class="ic i-angle-right"></i> <span class="current" itemprop="itemListElement" itemscope itemtype="https://schema.org/ListItem"><a href="/categories/%E5%AF%AB%E5%BE%88%E7%88%9B%E7%B3%BB%E5%88%97/%E6%B7%B1%E5%BA%A6%E5%AD%B8%E7%BF%92AI/" itemprop="item" rel="index" title="分類於 深度學習 AI"><span itemprop="name">深度學習 AI</span></a><meta itemprop="position" content="2"></span></div><article itemscope itemtype="http://schema.org/Article" class="post block" lang="zh-TW"><link itemprop="mainEntityOfPage" href="https://zrn-code.github.io/2020/04/09/AI-4/"><span hidden itemprop="author" itemscope itemtype="http://schema.org/Person"><meta itemprop="image" content="/images/avatar.jpg"><meta itemprop="name" content="Zrn（*゜ー゜*）"><meta itemprop="description" content="學習歷程, 再苦再累也要堅強，只為那些期待眼神"></span><span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization"><meta itemprop="name" content="永不停歇"></span><div class="body md" itemprop="articleBody"><h1 id="資料預處理"><a class="anchor" href="#資料預處理">#</a> 資料預處理</h1><h2 id="匯入所需的模組"><a class="anchor" href="#匯入所需的模組">#</a> 匯入所需的模組</h2><figure class="highlight python"><figcaption data-lang="python"></figcaption><table><tr><td data-num="1"></td><td><pre><span class="token keyword">from</span> keras<span class="token punctuation">.</span>datasets <span class="token keyword">import</span> mnist</pre></td></tr><tr><td data-num="2"></td><td><pre><span class="token keyword">from</span> keras<span class="token punctuation">.</span>utils <span class="token keyword">import</span> np_utils</pre></td></tr><tr><td data-num="3"></td><td><pre><span class="token keyword">import</span> numpy <span class="token keyword">as</span> np</pre></td></tr><tr><td data-num="4"></td><td><pre>np<span class="token punctuation">.</span>random<span class="token punctuation">.</span>seed<span class="token punctuation">(</span><span class="token number">10</span><span class="token punctuation">)</span></pre></td></tr></table></figure><h2 id="讀取mnist資料"><a class="anchor" href="#讀取mnist資料">#</a> 讀取 mnist 資料</h2><pre><code class="language-python">from keras.datasets import mnist
(x_train_image,y_train_label),\
(x_test_image,y_test_label)  =  mnist.load_data()
</code></pre><h2 id="將feature用reshape轉換"><a class="anchor" href="#將feature用reshape轉換">#</a> 將 feature 用 reshape 轉換</h2><p>將原本 28×28 的 2 為數字影像，以 reshape 轉換為 1 維的向量，在使用 astype 轉換為 float，共 784 個 float。</p><figure class="highlight python"><figcaption data-lang="python"></figcaption><table><tr><td data-num="1"></td><td><pre>x_train <span class="token operator">=</span> x_train_image<span class="token punctuation">.</span>reshape<span class="token punctuation">(</span><span class="token number">60000</span><span class="token punctuation">,</span> <span class="token number">784</span><span class="token punctuation">)</span><span class="token punctuation">.</span>astype<span class="token punctuation">(</span><span class="token string">'float32'</span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="2"></td><td><pre>x_test  <span class="token operator">=</span> x_test_image<span class="token punctuation">.</span>reshape<span class="token punctuation">(</span><span class="token number">10000</span><span class="token punctuation">,</span><span class="token number">784</span><span class="token punctuation">)</span><span class="token punctuation">.</span>astype<span class="token punctuation">(</span><span class="token string">'float32'</span><span class="token punctuation">)</span></pre></td></tr></table></figure><p>執行完後，可以看到大部分的數字都是 0，少部分有數字。數字都是由 0 至 255，表示一點的灰階深淺。</p><h2 id="將feature標準化"><a class="anchor" href="#將feature標準化">#</a> 將 feature 標準化</h2><p>image 的數字標準化，可以提高後續訓練模型的準確率，經標準化後數字都介於 0 至 1 之間。</p><figure class="highlight python"><figcaption data-lang="python"></figcaption><table><tr><td data-num="1"></td><td><pre>x_train_normalize <span class="token operator">=</span> x_train <span class="token operator">/</span><span class="token number">255</span></pre></td></tr><tr><td data-num="2"></td><td><pre>x_test_normalize <span class="token operator">=</span> x_test <span class="token operator">/</span><span class="token number">255</span></pre></td></tr></table></figure><h2 id="label以one-hot-encoding轉換"><a class="anchor" href="#label以one-hot-encoding轉換">#</a> label 以 One-hot encoding 轉換</h2><p>label 欄位原本是 0 至 9 的數字，必須轉換為 10 個 0 與 1 的組合，分別對應到 10 個輸出神經元。<br>例如：數字 5 經轉換後會是 0000010000</p><figure class="highlight python"><figcaption data-lang="python"></figcaption><table><tr><td data-num="1"></td><td><pre>y_train_onehot <span class="token operator">=</span> np_utils<span class="token punctuation">.</span>to_categorical<span class="token punctuation">(</span>y_train_label<span class="token punctuation">)</span></pre></td></tr><tr><td data-num="2"></td><td><pre>y_test_onehot <span class="token operator">=</span> np_utils<span class="token punctuation">.</span>to_categorical<span class="token punctuation">(</span>y_test_label<span class="token punctuation">)</span></pre></td></tr></table></figure><h1 id="建立模型"><a class="anchor" href="#建立模型">#</a> 建立模型</h1><h2 id="匯入所需的模組-2"><a class="anchor" href="#匯入所需的模組-2">#</a> 匯入所需的模組</h2><figure class="highlight python"><figcaption data-lang="python"></figcaption><table><tr><td data-num="1"></td><td><pre><span class="token keyword">from</span> keras<span class="token punctuation">.</span>models <span class="token keyword">import</span> Sequential</pre></td></tr><tr><td data-num="2"></td><td><pre><span class="token keyword">from</span> keras<span class="token punctuation">.</span>layers <span class="token keyword">import</span> Dense</pre></td></tr></table></figure><h2 id="建立sequential模型"><a class="anchor" href="#建立sequential模型">#</a> 建立 Sequential 模型</h2><p>建立一個線性堆疊模型，以後只要用 model.add () 就能將神經網路層加入模型。</p><figure class="highlight python"><figcaption data-lang="python"></figcaption><table><tr><td data-num="1"></td><td><pre>model <span class="token operator">=</span> Sequential<span class="token punctuation">(</span><span class="token punctuation">)</span></pre></td></tr></table></figure><h2 id="建立-輸入層-與-隱藏層"><a class="anchor" href="#建立-輸入層-與-隱藏層">#</a> 建立 輸入層 與 隱藏層</h2><p>使用 model.add () 加入 Dense 神經網路層。Dense 神經網路的特色是所有上一層與下一層的神經元，都完全連結。</p><figure class="highlight python"><figcaption data-lang="python"></figcaption><table><tr><td data-num="1"></td><td><pre>model<span class="token punctuation">.</span>add<span class="token punctuation">(</span>Dense<span class="token punctuation">(</span>units <span class="token operator">=</span> <span class="token number">256</span><span class="token punctuation">,</span>input_dim  <span class="token operator">=</span><span class="token number">784</span><span class="token punctuation">,</span>kernel_initializer <span class="token operator">=</span> <span class="token string">'normal'</span><span class="token punctuation">,</span>activation <span class="token operator">=</span> <span class="token string">'relu'</span><span class="token punctuation">)</span><span class="token punctuation">)</span></pre></td></tr></table></figure><h2 id="建立輸出層"><a class="anchor" href="#建立輸出層">#</a> 建立輸出層</h2><p>使用 model.add () 加入 Dense 神經網路層，共有 10 個神經元，對應到 0 到 9 個數字。並使用 softmax 進行轉換，softmax 可以將神經元的輸出轉化成預測每個數字的機率。</p><figure class="highlight python"><figcaption data-lang="python"></figcaption><table><tr><td data-num="1"></td><td><pre>model<span class="token punctuation">.</span>add<span class="token punctuation">(</span>Dense<span class="token punctuation">(</span>units <span class="token operator">=</span> <span class="token number">10</span><span class="token punctuation">,</span>kernel_initializer <span class="token operator">=</span> <span class="token string">'normal'</span><span class="token punctuation">,</span>activation <span class="token operator">=</span> <span class="token string">'softmax'</span><span class="token punctuation">)</span><span class="token punctuation">)</span></pre></td></tr></table></figure><h2 id="查看模型摘要"><a class="anchor" href="#查看模型摘要">#</a> 查看模型摘要</h2><figure class="highlight python"><figcaption data-lang="python"></figcaption><table><tr><td data-num="1"></td><td><pre><span class="token keyword">print</span><span class="token punctuation">(</span>model<span class="token punctuation">.</span>summary<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span></pre></td></tr></table></figure><p><img data-src="https://zrn-coding.github.io/img/summary.png?raw=true" alt=""><br>共有 2 個層:</p><ul><li>隱藏層：共有 256 個神經元。輸入層與隱藏層共同建立所以沒有顯示輸入層</li><li>輸出層：共有 10 個神經元</li></ul><p>每一層 Param 計算方式為: Param = (上一層神經元數量)×(本層神經元數量)+(本層神經元數量)</p><ul><li>隱藏層的 Param 是 200960，就是因為 (784) × (256) + (256) = 200960</li><li>輸出層的 Param 是 2570，就是因為 (256) × (10) + (10) = 2570</li></ul><p>全部需要訓練的超參數 (Trainable params)，是每一層的總和: 200960+2570 = 203530<br>通常而言，Trainable params 越大， 訓練的時間越長</p><h1 id="進行訓練"><a class="anchor" href="#進行訓練">#</a> 進行訓練</h1><h2 id="定義訓練方式"><a class="anchor" href="#定義訓練方式">#</a> 定義訓練方式</h2><p>在訓練之前，我們必須用 compile 對訓練的模型進行設定。</p><figure class="highlight python"><figcaption data-lang="python"></figcaption><table><tr><td data-num="1"></td><td><pre>model<span class="token punctuation">.</span><span class="token builtin">compile</span><span class="token punctuation">(</span> loss <span class="token operator">=</span> <span class="token string">'categorical_crossentropy'</span> <span class="token punctuation">,</span>optimizer<span class="token operator">=</span><span class="token string">'adam'</span><span class="token punctuation">,</span>metrics<span class="token operator">=</span><span class="token punctuation">[</span><span class="token string">'accuracy'</span><span class="token punctuation">]</span><span class="token punctuation">)</span></pre></td></tr></table></figure><ul><li>loss: 損失函數，在深度學習中使用 cross_entropy 訓練效果較好</li><li>optimizer: 訓練優化的方式，使用 adam 最優化方式，可以收斂得更快，並提高準確度</li><li>metrics: 設定評估模型的方式是 accuracy 準確率</li></ul><h2 id="開始訓練"><a class="anchor" href="#開始訓練">#</a> 開始訓練</h2><figure class="highlight python"><figcaption data-lang="python"></figcaption><table><tr><td data-num="1"></td><td><pre>train_history <span class="token operator">=</span>model<span class="token punctuation">.</span>fit<span class="token punctuation">(</span>x<span class="token operator">=</span>x_train_normalize<span class="token punctuation">,</span>y <span class="token operator">=</span> y_train_onehot<span class="token punctuation">,</span>validation_split<span class="token operator">=</span><span class="token number">0.2</span><span class="token punctuation">,</span>epochs<span class="token operator">=</span><span class="token number">10</span><span class="token punctuation">,</span>batch_size<span class="token operator">=</span><span class="token number">200</span><span class="token punctuation">,</span>verbose<span class="token operator">=</span><span class="token number">2</span><span class="token punctuation">)</span></pre></td></tr></table></figure><ol><li>輸入訓練資料<ul><li>x=x_train_normalize</li><li>y = y_train_onehot</li></ul></li><li>設定訓練與驗證資料比例<ul><li>validation_split= 0.2<br>訓練之前 Keras 會自動將資料分成: 80% 作為訓練、20% 作為驗證<br>總共有 60000 筆資料，所以有 48000 訓練、12000 筆做驗證</li></ul></li><li>設定 epoch 次數與每一批筆數<ul><li>epochs=10，執行 10 次訓練週期</li><li>batch_size=200，每一批次 200 筆資料</li></ul></li><li>顯示訓練過程<br><img data-src="https://zrn-coding.github.io/img/epoch.png" alt=""><br>loss、acc 是<strong>訓練資料的</strong>偏差及準確，val_loss、val_acc 則為<strong>驗證資料的</strong>偏差及準確<br>由上圖可得知，訓練次數越多，loss 誤差就越小，準確率越高</li></ol><h2 id="製作訓練過程圖表"><a class="anchor" href="#製作訓練過程圖表">#</a> 製作訓練過程圖表</h2><figure class="highlight python"><figcaption data-lang="python"></figcaption><table><tr><td data-num="1"></td><td><pre><span class="token keyword">import</span> matplotlib<span class="token punctuation">.</span>pyplot <span class="token keyword">as</span> plt</pre></td></tr><tr><td data-num="2"></td><td><pre><span class="token keyword">def</span> <span class="token function">show_train_history</span><span class="token punctuation">(</span>train_history<span class="token punctuation">,</span>train<span class="token punctuation">,</span>validation<span class="token punctuation">)</span><span class="token punctuation">:</span></pre></td></tr><tr><td data-num="3"></td><td><pre>    plt<span class="token punctuation">.</span>plot<span class="token punctuation">(</span>train_history<span class="token punctuation">.</span>history<span class="token punctuation">[</span>train<span class="token punctuation">]</span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="4"></td><td><pre>    plt<span class="token punctuation">.</span>plot<span class="token punctuation">(</span>train_history<span class="token punctuation">.</span>history<span class="token punctuation">[</span>validation<span class="token punctuation">]</span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="5"></td><td><pre>    plt<span class="token punctuation">.</span>title<span class="token punctuation">(</span><span class="token string">'Train History'</span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="6"></td><td><pre>    plt<span class="token punctuation">.</span>ylabel<span class="token punctuation">(</span>train<span class="token punctuation">)</span></pre></td></tr><tr><td data-num="7"></td><td><pre>    plt<span class="token punctuation">.</span>xlabel<span class="token punctuation">(</span><span class="token string">'Epoch'</span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="8"></td><td><pre>    plt<span class="token punctuation">.</span>legend<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token string">'train'</span><span class="token punctuation">,</span><span class="token string">'validation'</span><span class="token punctuation">]</span><span class="token punctuation">,</span>loc <span class="token operator">=</span> <span class="token string">'upper left'</span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="9"></td><td><pre>    plt<span class="token punctuation">.</span>show<span class="token punctuation">(</span><span class="token punctuation">)</span></pre></td></tr></table></figure><h2 id="畫出accuracy執行結果"><a class="anchor" href="#畫出accuracy執行結果">#</a> 畫出 accuracy 執行結果</h2><figure class="highlight python"><figcaption data-lang="python"></figcaption><table><tr><td data-num="1"></td><td><pre>show_train_history<span class="token punctuation">(</span>train_history<span class="token punctuation">,</span><span class="token string">'acc'</span><span class="token punctuation">,</span><span class="token string">'val_acc'</span><span class="token punctuation">)</span></pre></td></tr></table></figure><p><img data-src="https://Zrn-coding.github.io/img/train_acc.png" alt=""><br>上圖的，橘色為預測，藍色為訓練<br>由上圖可看出:</p><ol><li>訓練與驗證時的準確度會隨著訓練次數變多而增加</li><li>訓練到了後期，<strong>訓練時的準確率</strong> 比 <strong>驗證時的準確率 高</strong></li></ol><p>為什麼會<strong>訓練時的準確率</strong> 比 <strong>驗證時的準確率 高</strong>呢？這種現象被稱之為<strong>過度擬合 Overfitting</strong><br><img data-src="https://ithelp.ithome.com.tw/upload/images/20181020/20112540PwCCbhGvkb.png" alt=""><br>簡單而言，就是<strong>訓練時的準確率太高</strong>經過太多次的訓練後，區分的線會漸漸的變形，變得太過扭曲，進而讓測資變得不準</p><h2 id="畫出loss誤差執行結果"><a class="anchor" href="#畫出loss誤差執行結果">#</a> 畫出 loss 誤差執行結果</h2><figure class="highlight python"><figcaption data-lang="python"></figcaption><table><tr><td data-num="1"></td><td><pre>show_train_history<span class="token punctuation">(</span>train_history<span class="token punctuation">,</span><span class="token string">'loss'</span><span class="token punctuation">,</span><span class="token string">'val_loss'</span><span class="token punctuation">)</span></pre></td></tr></table></figure><p><img data-src="https://Zrn-coding.github.io/img/train_loss.png" alt=""><br>上圖的，橘色為預測，藍色為訓練<br>由上圖可看出:</p><ol><li>訓練與驗證時的準確度會隨著訓練次數變多而減少</li><li>訓練到了後期，<strong>訓練時的偏差</strong> 比 <strong>驗證時的偏差 低</strong><br>一樣有 Overfitting 的問題產生</li></ol><h1 id="評估模型準確率"><a class="anchor" href="#評估模型準確率">#</a> 評估模型準確率</h1><p>使用 test 測試資料，評估模型準確度</p><figure class="highlight python"><figcaption data-lang="python"></figcaption><table><tr><td data-num="1"></td><td><pre>scores <span class="token operator">=</span> model<span class="token punctuation">.</span>evaluate<span class="token punctuation">(</span>x_Test_normalize<span class="token punctuation">,</span> y_Test_OneHot<span class="token punctuation">)</span></pre></td></tr><tr><td data-num="2"></td><td><pre><span class="token keyword">print</span><span class="token punctuation">(</span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="3"></td><td><pre><span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'accuracy='</span><span class="token punctuation">,</span>score<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">)</span></pre></td></tr></table></figure><h1 id="進行預測"><a class="anchor" href="#進行預測">#</a> 進行預測</h1><h2 id="執行預測"><a class="anchor" href="#執行預測">#</a> 執行預測</h2><figure class="highlight python"><figcaption data-lang="python"></figcaption><table><tr><td data-num="1"></td><td><pre>prediction <span class="token operator">=</span> model<span class="token punctuation">.</span>predict_classes<span class="token punctuation">(</span>x_test<span class="token punctuation">)</span></pre></td></tr></table></figure><h2 id="預測結果"><a class="anchor" href="#預測結果">#</a> 預測結果</h2><figure class="highlight python"><figcaption data-lang="python"></figcaption><table><tr><td data-num="1"></td><td><pre>prediction</pre></td></tr></table></figure><h1 id="顯示混淆矩陣"><a class="anchor" href="#顯示混淆矩陣">#</a> 顯示混淆矩陣</h1><figure class="highlight python"><figcaption data-lang="python"></figcaption><table><tr><td data-num="1"></td><td><pre><span class="token keyword">import</span> pandas <span class="token keyword">as</span> pd</pre></td></tr><tr><td data-num="2"></td><td><pre>pd<span class="token punctuation">.</span>crosstab<span class="token punctuation">(</span>y_test_label<span class="token punctuation">,</span>prediction<span class="token punctuation">,</span>rownames<span class="token operator">=</span><span class="token punctuation">[</span><span class="token string">'label'</span><span class="token punctuation">]</span><span class="token punctuation">,</span>colnames<span class="token operator">=</span><span class="token punctuation">[</span><span class="token string">'predict'</span><span class="token punctuation">]</span><span class="token punctuation">)</span></pre></td></tr></table></figure><p><img data-src="https://zrn-coding.github.io/img/confusion.png" alt=""><br>上排為預測出來的結果，左邊為真實的值，而對角線的數字代表預測正確的數量</p><h1 id="增加隱藏層的神經元"><a class="anchor" href="#增加隱藏層的神經元">#</a> 增加隱藏層的神經元</h1><h2 id="增加神經元"><a class="anchor" href="#增加神經元">#</a> 增加神經元</h2><p>我們將原本 256 個神經元 (units) 調整為 1000 個神經元</p><figure class="highlight python"><figcaption data-lang="python"></figcaption><table><tr><td data-num="1"></td><td><pre>model<span class="token punctuation">.</span>add<span class="token punctuation">(</span>Dense<span class="token punctuation">(</span>units <span class="token operator">=</span> <span class="token number">1000</span><span class="token punctuation">,</span>input_dim  <span class="token operator">=</span><span class="token number">784</span><span class="token punctuation">,</span>kernel_initializer <span class="token operator">=</span> <span class="token string">'normal'</span><span class="token punctuation">,</span>activation <span class="token operator">=</span> <span class="token string">'relu'</span><span class="token punctuation">)</span><span class="token punctuation">)</span></pre></td></tr></table></figure><h2 id="查看模型"><a class="anchor" href="#查看模型">#</a> 查看模型</h2><figure class="highlight python"><figcaption data-lang="python"></figcaption><table><tr><td data-num="1"></td><td><pre><span class="token keyword">print</span><span class="token punctuation">(</span>model<span class="token punctuation">.</span>summary<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span></pre></td></tr></table></figure><p><img data-src="https://Zrn-coding.github.io/img/summary_2.png" alt=""></p><h2 id="開始訓練-2"><a class="anchor" href="#開始訓練-2">#</a> 開始訓練</h2><figure class="highlight python"><figcaption data-lang="python"></figcaption><table><tr><td data-num="1"></td><td><pre>train_history <span class="token operator">=</span>model<span class="token punctuation">.</span>fit<span class="token punctuation">(</span>x<span class="token operator">=</span>x_train_normalize<span class="token punctuation">,</span>y <span class="token operator">=</span> y_train_onehot<span class="token punctuation">,</span>validation_split<span class="token operator">=</span><span class="token number">0.2</span><span class="token punctuation">,</span>epochs<span class="token operator">=</span><span class="token number">10</span><span class="token punctuation">,</span>batch_size<span class="token operator">=</span><span class="token number">200</span><span class="token punctuation">,</span>verbose<span class="token operator">=</span><span class="token number">2</span><span class="token punctuation">)</span></pre></td></tr></table></figure><p><img data-src="https://Zrn-coding.github.io/img/epoch_2.png" alt=""></p><h2 id="畫出accuracy執行結果-2"><a class="anchor" href="#畫出accuracy執行結果-2">#</a> 畫出 accuracy 執行結果</h2><figure class="highlight python"><figcaption data-lang="python"></figcaption><table><tr><td data-num="1"></td><td><pre>show_train_history<span class="token punctuation">(</span>train_history<span class="token punctuation">,</span><span class="token string">'acc'</span><span class="token punctuation">,</span><span class="token string">'val_acc'</span><span class="token punctuation">)</span></pre></td></tr></table></figure><p><img data-src="https://Zrn-coding.github.io/img/train_acc_2.png" alt=""></p><p>上圖的，橘色為預測，藍色為訓練<br>由上圖可看出:</p><ol><li>訓練與驗證時的準確度會隨著訓練次數變多而增加</li><li>訓練到了後期，<strong>訓練時的準確率</strong> 比 <strong>驗證時的準確率 高</strong></li><li><strong>Overfitting 問題</strong>比原本的<strong>更加嚴重</strong></li></ol><h1 id="解決overfitting問題"><a class="anchor" href="#解決overfitting問題">#</a> 解決 Overfitting 問題</h1><p>為了解決 Overfitting 問題，會加入 Dropout 指令，意思是指每次做訓練時，會隨機拋棄部分神經元，以解決過度與數據擬合。</p><h2 id="在隱藏層中加入dropout功能"><a class="anchor" href="#在隱藏層中加入dropout功能">#</a> 在隱藏層中加入 DropOut 功能</h2><figure class="highlight python"><figcaption data-lang="python"></figcaption><table><tr><td data-num="1"></td><td><pre><span class="token keyword">from</span> keras<span class="token punctuation">.</span>models <span class="token keyword">import</span> Sequential</pre></td></tr><tr><td data-num="2"></td><td><pre><span class="token keyword">from</span> keras<span class="token punctuation">.</span>layers <span class="token keyword">import</span> Dense</pre></td></tr><tr><td data-num="3"></td><td><pre><span class="token operator">+</span> <span class="token keyword">from</span> keras<span class="token punctuation">.</span>layers <span class="token keyword">import</span> Dropout</pre></td></tr><tr><td data-num="4"></td><td><pre></pre></td></tr><tr><td data-num="5"></td><td><pre>model <span class="token operator">=</span> Sequential<span class="token punctuation">(</span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="6"></td><td><pre><span class="token comment">#輸入層 + 隱藏層</span></pre></td></tr><tr><td data-num="7"></td><td><pre>model<span class="token punctuation">.</span>add<span class="token punctuation">(</span>Dense<span class="token punctuation">(</span>units <span class="token operator">=</span> <span class="token number">1000</span><span class="token punctuation">,</span>input_dim  <span class="token operator">=</span><span class="token number">784</span><span class="token punctuation">,</span>kernel_initializer <span class="token operator">=</span> <span class="token string">'normal'</span><span class="token punctuation">,</span>activation <span class="token operator">=</span> <span class="token string">'relu'</span><span class="token punctuation">)</span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="8"></td><td><pre></pre></td></tr><tr><td data-num="9"></td><td><pre><span class="token operator">+</span> model<span class="token punctuation">.</span>add<span class="token punctuation">(</span>Dropout<span class="token punctuation">(</span><span class="token number">0.5</span><span class="token punctuation">)</span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="10"></td><td><pre><span class="token comment">#輸出層</span></pre></td></tr><tr><td data-num="11"></td><td><pre>model<span class="token punctuation">.</span>add<span class="token punctuation">(</span>Dense<span class="token punctuation">(</span>units <span class="token operator">=</span> <span class="token number">10</span><span class="token punctuation">,</span>kernel_initializer <span class="token operator">=</span> <span class="token string">'normal'</span><span class="token punctuation">,</span>activation <span class="token operator">=</span> <span class="token string">'softmax'</span><span class="token punctuation">)</span><span class="token punctuation">)</span></pre></td></tr></table></figure><h2 id="查看模型-2"><a class="anchor" href="#查看模型-2">#</a> 查看模型</h2><figure class="highlight python"><figcaption data-lang="python"></figcaption><table><tr><td data-num="1"></td><td><pre><span class="token keyword">print</span><span class="token punctuation">(</span>model<span class="token punctuation">.</span>summary<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span></pre></td></tr></table></figure><p><img data-src="https://Zrn-coding.github.io/img/summary_3.png" alt=""></p><h2 id="開始訓練-3"><a class="anchor" href="#開始訓練-3">#</a> 開始訓練</h2><figure class="highlight python"><figcaption data-lang="python"></figcaption><table><tr><td data-num="1"></td><td><pre>train_history <span class="token operator">=</span>model<span class="token punctuation">.</span>fit<span class="token punctuation">(</span>x<span class="token operator">=</span>x_train_normalize<span class="token punctuation">,</span>y <span class="token operator">=</span> y_train_onehot<span class="token punctuation">,</span>validation_split<span class="token operator">=</span><span class="token number">0.2</span><span class="token punctuation">,</span>epochs<span class="token operator">=</span><span class="token number">10</span><span class="token punctuation">,</span>batch_size<span class="token operator">=</span><span class="token number">200</span><span class="token punctuation">,</span>verbose<span class="token operator">=</span><span class="token number">2</span><span class="token punctuation">)</span></pre></td></tr></table></figure><p><img data-src="https://Zrn-coding.github.io/img/epoch_3.png" alt=""><br>在最後一次的數據中可以看出差距有變得更小了</p><h2 id="畫出accuracy執行結果-3"><a class="anchor" href="#畫出accuracy執行結果-3">#</a> 畫出 accuracy 執行結果</h2><figure class="highlight python"><figcaption data-lang="python"></figcaption><table><tr><td data-num="1"></td><td><pre>show_train_history<span class="token punctuation">(</span>train_history<span class="token punctuation">,</span><span class="token string">'acc'</span><span class="token punctuation">,</span><span class="token string">'val_acc'</span><span class="token punctuation">)</span></pre></td></tr></table></figure><p><img data-src="https://Zrn-coding.github.io/img/train_acc_3.png" alt=""></p><p>上圖的，橘色為預測，藍色為訓練<br>由上圖可看出:</p><ol><li>訓練與驗證時的準確度會隨著訓練次數變多而增加</li><li>訓練到了後期，<strong>訓練時的準確率</strong> 比 <strong>驗證時的準確率 高</strong></li><li>Overfitting 的問題已經有減輕了些</li></ol><h2 id="小結"><a class="anchor" href="#小結">#</a> 小結</h2><p>加入 DropOut 功能可以有效降低數據的過度擬合，甚至可以增加預測的成功率</p><h1 id="再加入一層隱藏層"><a class="anchor" href="#再加入一層隱藏層">#</a> 再加入一層隱藏層</h1><p>為了近一步的增加準確率，可以再增加一層的隱藏層</p><h2 id="建立隱藏層"><a class="anchor" href="#建立隱藏層">#</a> 建立隱藏層</h2><figure class="highlight python"><figcaption data-lang="python"></figcaption><table><tr><td data-num="1"></td><td><pre>model <span class="token operator">=</span> Sequential<span class="token punctuation">(</span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="2"></td><td><pre><span class="token comment">#輸入層 + 第一層隱藏層</span></pre></td></tr><tr><td data-num="3"></td><td><pre>model<span class="token punctuation">.</span>add<span class="token punctuation">(</span>Dense<span class="token punctuation">(</span>units <span class="token operator">=</span> <span class="token number">1000</span><span class="token punctuation">,</span>input_dim  <span class="token operator">=</span><span class="token number">784</span><span class="token punctuation">,</span>kernel_initializer <span class="token operator">=</span> <span class="token string">'normal'</span><span class="token punctuation">,</span>activation <span class="token operator">=</span> <span class="token string">'relu'</span><span class="token punctuation">)</span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="4"></td><td><pre>model<span class="token punctuation">.</span>add<span class="token punctuation">(</span>Dropout<span class="token punctuation">(</span><span class="token number">0.5</span><span class="token punctuation">)</span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="5"></td><td><pre><span class="token comment">#第二層隱藏層</span></pre></td></tr><tr><td data-num="6"></td><td><pre><span class="token operator">+</span> model<span class="token punctuation">.</span>add<span class="token punctuation">(</span>Dense<span class="token punctuation">(</span>units <span class="token operator">=</span> <span class="token number">1000</span><span class="token punctuation">,</span>kernel_initializer <span class="token operator">=</span> <span class="token string">'normal'</span><span class="token punctuation">,</span>activation <span class="token operator">=</span> <span class="token string">'relu'</span><span class="token punctuation">)</span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="7"></td><td><pre><span class="token operator">+</span> model<span class="token punctuation">.</span>add<span class="token punctuation">(</span>Dropout<span class="token punctuation">(</span><span class="token number">0.5</span><span class="token punctuation">)</span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="8"></td><td><pre><span class="token comment">#輸出層</span></pre></td></tr><tr><td data-num="9"></td><td><pre>model<span class="token punctuation">.</span>add<span class="token punctuation">(</span>Dense<span class="token punctuation">(</span>units <span class="token operator">=</span> <span class="token number">10</span><span class="token punctuation">,</span>kernel_initializer <span class="token operator">=</span> <span class="token string">'normal'</span><span class="token punctuation">,</span>activation <span class="token operator">=</span> <span class="token string">'softmax'</span><span class="token punctuation">)</span><span class="token punctuation">)</span></pre></td></tr></table></figure><h2 id="查看模型-3"><a class="anchor" href="#查看模型-3">#</a> 查看模型</h2><figure class="highlight python"><figcaption data-lang="python"></figcaption><table><tr><td data-num="1"></td><td><pre><span class="token keyword">print</span><span class="token punctuation">(</span>model<span class="token punctuation">.</span>summary<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span></pre></td></tr></table></figure><p><img data-src="https://Zrn-coding.github.io/img/summary_4.png" alt=""></p><h2 id="畫出accuracy執行結果-4"><a class="anchor" href="#畫出accuracy執行結果-4">#</a> 畫出 accuracy 執行結果</h2><figure class="highlight python"><figcaption data-lang="python"></figcaption><table><tr><td data-num="1"></td><td><pre>show_train_history<span class="token punctuation">(</span>train_history<span class="token punctuation">,</span><span class="token string">'acc'</span><span class="token punctuation">,</span><span class="token string">'val_acc'</span><span class="token punctuation">)</span></pre></td></tr></table></figure><p><img data-src="https://Zrn-coding.github.io/img/train_acc_4.png" alt=""></p><p>上圖的，橘色為預測，藍色為訓練<br>由上圖可看出:</p><ol><li>訓練與驗證時的準確度會隨著訓練次數變多而增加</li><li>訓練到了後期，<strong>訓練時的準確率</strong> 比 <strong>驗證時的準確率 高</strong></li><li>Overfitting 的問題已經有減輕很多了，大致上已經解決了</li></ol><h2 id="小結-2"><a class="anchor" href="#小結-2">#</a> 小結</h2><p>再增加了一層的隱藏層對於預測準確率而言，已經沒有什麼明顯的提升了</p><div class="tags"><a href="/tags/AI/" rel="tag"><i class="ic i-tag"></i> AI</a> <a href="/tags/%E6%B7%B1%E5%BA%A6%E5%AD%B8%E7%BF%92/" rel="tag"><i class="ic i-tag"></i> 深度學習</a> <a href="/tags/%E5%AF%A6%E4%BD%9CAI/" rel="tag"><i class="ic i-tag"></i> 實作AI</a> <a href="/tags/python/" rel="tag"><i class="ic i-tag"></i> python</a> <a href="/tags/%E6%89%8B%E5%AF%AB%E8%BE%A8%E8%AD%98/" rel="tag"><i class="ic i-tag"></i> 手寫辨識</a> <a href="/tags/keras/" rel="tag"><i class="ic i-tag"></i> keras</a></div></div><footer><div class="meta"><span class="item"><span class="icon"><i class="ic i-calendar-check"></i> </span><span class="text">更新於</span> <time title="修改時間：2021-06-29 14:19:18" itemprop="dateModified" datetime="2021-06-29T14:19:18+08:00">2021-06-29</time> </span><span id="2020/04/09/AI-4/" class="item leancloud_visitors" data-flag-title="第 04 篇、Keras MLP 辨識手寫數字" title="閱讀次數"><span class="icon"><i class="ic i-eye"></i> </span><span class="text">閱讀次數</span> <span class="leancloud-visitors-count"></span> <span class="text">次</span></span></div><div id="copyright"><ul><li class="author"><strong>作者： </strong>Zrn（*゜ー゜*） <i class="ic i-at"><em>@</em></i>永不停歇</li><li class="link"><strong>文章連結：</strong> <a href="https://zrn-code.github.io/2020/04/09/AI-4/" title="第 04 篇、Keras MLP 辨識手寫數字">https://zrn-code.github.io/2020/04/09/AI-4/</a></li><li class="license"><strong>版權聲明： </strong>本網誌所有文章除特別聲明外，均採用 <span class="exturl" data-url="aHR0cHM6Ly9jcmVhdGl2ZWNvbW1vbnMub3JnL2xpY2Vuc2VzL2J5LW5jLXNhLzQuMC9kZWVkLnpo"><i class="ic i-creative-commons"><em>(CC)</em></i>BY-NC-SA</span> 許可協議。轉載請註明出處！</li></ul></div></footer></article></div><div class="post-nav"><div class="item left"><a href="/2020/03/24/AI-3/" itemprop="url" rel="prev" data-background-image="https:&#x2F;&#x2F;tva2.sinaimg.cn&#x2F;mw690&#x2F;6833939bly1gipevo9j1jj20zk0m8e81.jpg" title="第03篇、Tensorflow與Keras介紹"><span class="type">上一篇</span> <span class="category"><i class="ic i-flag"></i> 深度學習 AI</span><h3>第03篇、Tensorflow與Keras介紹</h3></a></div><div class="item right"><a href="/2020/04/11/b964/" itemprop="url" rel="next" data-background-image="https:&#x2F;&#x2F;tva2.sinaimg.cn&#x2F;mw690&#x2F;6833939bly1gipevarprfj20zk0m8npd.jpg" title="b964: 第 1 題 成績指標"><span class="type">下一篇</span> <span class="category"><i class="ic i-flag"></i> Zerojudge</span><h3>b964: 第 1 題 成績指標</h3></a></div></div><div class="wrap" id="comments"></div></div><div id="sidebar"><div class="inner"><div class="panels"><div class="inner"><div class="contents panel pjax" data-title="文章目錄"><ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link" href="#%E8%B3%87%E6%96%99%E9%A0%90%E8%99%95%E7%90%86"><span class="toc-number">1.</span> <span class="toc-text">資料預處理</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%8C%AF%E5%85%A5%E6%89%80%E9%9C%80%E7%9A%84%E6%A8%A1%E7%B5%84"><span class="toc-number">1.1.</span> <span class="toc-text">匯入所需的模組</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E8%AE%80%E5%8F%96mnist%E8%B3%87%E6%96%99"><span class="toc-number">1.2.</span> <span class="toc-text">讀取 mnist 資料</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%B0%87feature%E7%94%A8reshape%E8%BD%89%E6%8F%9B"><span class="toc-number">1.3.</span> <span class="toc-text">將 feature 用 reshape 轉換</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%B0%87feature%E6%A8%99%E6%BA%96%E5%8C%96"><span class="toc-number">1.4.</span> <span class="toc-text">將 feature 標準化</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#label%E4%BB%A5one-hot-encoding%E8%BD%89%E6%8F%9B"><span class="toc-number">1.5.</span> <span class="toc-text">label 以 One-hot encoding 轉換</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#%E5%BB%BA%E7%AB%8B%E6%A8%A1%E5%9E%8B"><span class="toc-number">2.</span> <span class="toc-text">建立模型</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%8C%AF%E5%85%A5%E6%89%80%E9%9C%80%E7%9A%84%E6%A8%A1%E7%B5%84-2"><span class="toc-number">2.1.</span> <span class="toc-text">匯入所需的模組</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%BB%BA%E7%AB%8Bsequential%E6%A8%A1%E5%9E%8B"><span class="toc-number">2.2.</span> <span class="toc-text">建立 Sequential 模型</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%BB%BA%E7%AB%8B-%E8%BC%B8%E5%85%A5%E5%B1%A4-%E8%88%87-%E9%9A%B1%E8%97%8F%E5%B1%A4"><span class="toc-number">2.3.</span> <span class="toc-text">建立 輸入層 與 隱藏層</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%BB%BA%E7%AB%8B%E8%BC%B8%E5%87%BA%E5%B1%A4"><span class="toc-number">2.4.</span> <span class="toc-text">建立輸出層</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E6%9F%A5%E7%9C%8B%E6%A8%A1%E5%9E%8B%E6%91%98%E8%A6%81"><span class="toc-number">2.5.</span> <span class="toc-text">查看模型摘要</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#%E9%80%B2%E8%A1%8C%E8%A8%93%E7%B7%B4"><span class="toc-number">3.</span> <span class="toc-text">進行訓練</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%AE%9A%E7%BE%A9%E8%A8%93%E7%B7%B4%E6%96%B9%E5%BC%8F"><span class="toc-number">3.1.</span> <span class="toc-text">定義訓練方式</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E9%96%8B%E5%A7%8B%E8%A8%93%E7%B7%B4"><span class="toc-number">3.2.</span> <span class="toc-text">開始訓練</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E8%A3%BD%E4%BD%9C%E8%A8%93%E7%B7%B4%E9%81%8E%E7%A8%8B%E5%9C%96%E8%A1%A8"><span class="toc-number">3.3.</span> <span class="toc-text">製作訓練過程圖表</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E7%95%AB%E5%87%BAaccuracy%E5%9F%B7%E8%A1%8C%E7%B5%90%E6%9E%9C"><span class="toc-number">3.4.</span> <span class="toc-text">畫出 accuracy 執行結果</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E7%95%AB%E5%87%BAloss%E8%AA%A4%E5%B7%AE%E5%9F%B7%E8%A1%8C%E7%B5%90%E6%9E%9C"><span class="toc-number">3.5.</span> <span class="toc-text">畫出 loss 誤差執行結果</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#%E8%A9%95%E4%BC%B0%E6%A8%A1%E5%9E%8B%E6%BA%96%E7%A2%BA%E7%8E%87"><span class="toc-number">4.</span> <span class="toc-text">評估模型準確率</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#%E9%80%B2%E8%A1%8C%E9%A0%90%E6%B8%AC"><span class="toc-number">5.</span> <span class="toc-text">進行預測</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%9F%B7%E8%A1%8C%E9%A0%90%E6%B8%AC"><span class="toc-number">5.1.</span> <span class="toc-text">執行預測</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E9%A0%90%E6%B8%AC%E7%B5%90%E6%9E%9C"><span class="toc-number">5.2.</span> <span class="toc-text">預測結果</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#%E9%A1%AF%E7%A4%BA%E6%B7%B7%E6%B7%86%E7%9F%A9%E9%99%A3"><span class="toc-number">6.</span> <span class="toc-text">顯示混淆矩陣</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#%E5%A2%9E%E5%8A%A0%E9%9A%B1%E8%97%8F%E5%B1%A4%E7%9A%84%E7%A5%9E%E7%B6%93%E5%85%83"><span class="toc-number">7.</span> <span class="toc-text">增加隱藏層的神經元</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%A2%9E%E5%8A%A0%E7%A5%9E%E7%B6%93%E5%85%83"><span class="toc-number">7.1.</span> <span class="toc-text">增加神經元</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E6%9F%A5%E7%9C%8B%E6%A8%A1%E5%9E%8B"><span class="toc-number">7.2.</span> <span class="toc-text">查看模型</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E9%96%8B%E5%A7%8B%E8%A8%93%E7%B7%B4-2"><span class="toc-number">7.3.</span> <span class="toc-text">開始訓練</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E7%95%AB%E5%87%BAaccuracy%E5%9F%B7%E8%A1%8C%E7%B5%90%E6%9E%9C-2"><span class="toc-number">7.4.</span> <span class="toc-text">畫出 accuracy 執行結果</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#%E8%A7%A3%E6%B1%BAoverfitting%E5%95%8F%E9%A1%8C"><span class="toc-number">8.</span> <span class="toc-text">解決 Overfitting 問題</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%9C%A8%E9%9A%B1%E8%97%8F%E5%B1%A4%E4%B8%AD%E5%8A%A0%E5%85%A5dropout%E5%8A%9F%E8%83%BD"><span class="toc-number">8.1.</span> <span class="toc-text">在隱藏層中加入 DropOut 功能</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E6%9F%A5%E7%9C%8B%E6%A8%A1%E5%9E%8B-2"><span class="toc-number">8.2.</span> <span class="toc-text">查看模型</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E9%96%8B%E5%A7%8B%E8%A8%93%E7%B7%B4-3"><span class="toc-number">8.3.</span> <span class="toc-text">開始訓練</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E7%95%AB%E5%87%BAaccuracy%E5%9F%B7%E8%A1%8C%E7%B5%90%E6%9E%9C-3"><span class="toc-number">8.4.</span> <span class="toc-text">畫出 accuracy 執行結果</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%B0%8F%E7%B5%90"><span class="toc-number">8.5.</span> <span class="toc-text">小結</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#%E5%86%8D%E5%8A%A0%E5%85%A5%E4%B8%80%E5%B1%A4%E9%9A%B1%E8%97%8F%E5%B1%A4"><span class="toc-number">9.</span> <span class="toc-text">再加入一層隱藏層</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%BB%BA%E7%AB%8B%E9%9A%B1%E8%97%8F%E5%B1%A4"><span class="toc-number">9.1.</span> <span class="toc-text">建立隱藏層</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E6%9F%A5%E7%9C%8B%E6%A8%A1%E5%9E%8B-3"><span class="toc-number">9.2.</span> <span class="toc-text">查看模型</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E7%95%AB%E5%87%BAaccuracy%E5%9F%B7%E8%A1%8C%E7%B5%90%E6%9E%9C-4"><span class="toc-number">9.3.</span> <span class="toc-text">畫出 accuracy 執行結果</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%B0%8F%E7%B5%90-2"><span class="toc-number">9.4.</span> <span class="toc-text">小結</span></a></li></ol></li></ol></div><div class="related panel pjax" data-title="系列文章"><ul><li><a href="/2020/03/18/AI-1/" rel="bookmark" title="第01篇、基礎認識">第01篇、基礎認識</a></li><li><a href="/2020/03/21/AI-2/" rel="bookmark" title="第02篇、深度學習的原理">第02篇、深度學習的原理</a></li><li><a href="/2020/03/24/AI-3/" rel="bookmark" title="第03篇、Tensorflow與Keras介紹">第03篇、Tensorflow與Keras介紹</a></li><li class="active"><a href="/2020/04/09/AI-4/" rel="bookmark" title="第04篇、Keras MLP辨識手寫數字">第04篇、Keras MLP辨識手寫數字</a></li><li><a href="/2020/04/16/AI-5/" rel="bookmark" title="第05篇、CNN手寫辨識">第05篇、CNN手寫辨識</a></li><li><a href="/2020/04/23/AI-6/" rel="bookmark" title="第06篇、CNN辨識物體">第06篇、CNN辨識物體</a></li><li><a href="/2020/04/30/AI-7/" rel="bookmark" title="第07篇、IMDb情緒分析">第07篇、IMDb情緒分析</a></li><li><a href="/2020/05/21/AI-8/" rel="bookmark" title="第08篇、LSTM">第08篇、LSTM</a></li><li><a href="/2020/06/12/AI-9/" rel="bookmark" title="第09篇、圖片分割">第09篇、圖片分割</a></li><li><a href="/2020/07/15/AI-10/" rel="bookmark" title="第10篇、風格轉移">第10篇、風格轉移</a></li></ul></div><div class="overview panel" data-title="本站概要"><div class="author" itemprop="author" itemscope itemtype="http://schema.org/Person"><img class="image" itemprop="image" alt="Zrn（*゜ー゜*）" data-src="/images/avatar.jpg"><p class="name" itemprop="name">Zrn（*゜ー゜*）</p><div class="description" itemprop="description">再苦再累也要堅強，只為那些期待眼神</div></div><nav class="state"><div class="item posts"><a href="/archives/"><span class="count">384</span> <span class="name">文章</span></a></div><div class="item categories"><a href="/categories/"><span class="count">21</span> <span class="name">分類</span></a></div><div class="item tags"><a href="/tags/"><span class="count">128</span> <span class="name">標籤</span></a></div></nav><div class="social"><span class="exturl item github" data-url="aHR0cHM6Ly9naXRodWIuY29tL3pybi1jb2Rpbmc=" title="https:&#x2F;&#x2F;github.com&#x2F;zrn-coding"><i class="ic i-github"></i></span> <span class="exturl item email" data-url="bWFpbHRvOnp4YzA5Nzg4Mjc5MDlAbWFpbC5jb20=" title="mailto:zxc0978827909@mail.com"><i class="ic i-envelope"></i></span> <span class="exturl item about" data-url="aHR0cHM6Ly9hYm91dC5tZS96eGMwOTc4ODI3OTA5" title="https:&#x2F;&#x2F;about.me&#x2F;zxc0978827909"><i class="ic i-address-card"></i></span></div><ul class="menu"><li class="item"><a href="/" rel="section"><i class="ic i-home"></i>首頁</a></li><li class="item"><a href="/about/" rel="section"><i class="ic i-user"></i>關於</a></li><li class="item dropdown"><a href="javascript:void(0);"><i class="ic i-feather"></i>文章</a><ul class="submenu"><li class="item"><a href="/archives/" rel="section"><i class="ic i-list-alt"></i>歸檔</a></li><li class="item"><a href="/categories/" rel="section"><i class="ic i-th"></i>分類</a></li><li class="item"><a href="/tags/" rel="section"><i class="ic i-tags"></i>標籤</a></li></ul></li><li class="item"><a href="/friends/" rel="section"><i class="ic i-heart"></i>小夥伴</a></li><li class="item"><a href="/links/" rel="section"><i class="ic i-magic"></i>神奇連結</a></li></ul></div></div></div><ul id="quick"><li class="prev pjax"><a href="/2020/03/24/AI-3/" rel="prev" title="上一篇"><i class="ic i-chevron-left"></i></a></li><li class="up"><i class="ic i-arrow-up"></i></li><li class="down"><i class="ic i-arrow-down"></i></li><li class="next pjax"><a href="/2020/04/11/b964/" rel="next" title="下一篇"><i class="ic i-chevron-right"></i></a></li><li class="percent"></li></ul></div></div><div class="dimmer"></div></div></main><footer id="footer"><div class="inner"><div class="widgets"></div><div class="status"><div class="copyright">&copy; 2020 – <span itemprop="copyrightYear">2021</span> <span class="with-love"><i class="ic i-sakura rotate"></i> </span><span class="author" itemprop="copyrightHolder">Zrn（*゜ー゜*） @ Zrn Code</span></div><div class="count"><span class="post-meta-item-icon"><i class="ic i-chart-area"></i> </span><span title="總字數">516k 字</span> <span class="post-meta-divider">|</span> <span class="post-meta-item-icon"><i class="ic i-coffee"></i> </span><span title="所需總閱讀時間">7:50</span></div></div></div></footer></div><script data-config type="text/javascript">var LOCAL={path:"2020/04/09/AI-4/",favicon:{show:"（●´3｀●）復活成功",hide:"(´Д｀)瀏覽器崩潰啦"},search:{placeholder:"文章搜尋",empty:"關於 「 ${query} 」 ，什麼也沒搜到",stats:"${time} ms 內找到 ${hits} 條結果"},valine:!0,fancybox:!0,copyright:'複製成功，轉載請遵守 <i class="ic i-creative-commons"></i>BY-NC-SA 協議。',ignores:[function(e){return e.includes("#")},function(e){return new RegExp(LOCAL.path+"$").test(e)}]}</script><script src="https://cdn.polyfill.io/v2/polyfill.js"></script><script src="//cdn.jsdelivr.net/combine/npm/pace-js@1.0.2/pace.min.js,npm/pjax@0.2.8/pjax.min.js,npm/whatwg-fetch@3.4.0/dist/fetch.umd.min.js,npm/animejs@3.2.0/lib/anime.min.js,npm/algoliasearch@4/dist/algoliasearch-lite.umd.js,npm/instantsearch.js@4/dist/instantsearch.production.min.js,npm/lozad@1/dist/lozad.min.js,npm/quicklink@2/dist/quicklink.umd.js"></script><script src="/js/app.js?v=0.2.5"></script></body></html><!-- rebuild by hrmmi -->