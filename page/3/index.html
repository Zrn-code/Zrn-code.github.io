<!-- build time:Tue May 17 2022 09:49:12 GMT+0800 (台北標準時間) --><!DOCTYPE html><html lang="zh-TW"><head><meta charset="UTF-8"><meta name="viewport" content="width=device-width,initial-scale=1,maximum-scale=2"><meta name="theme-color" content="#FFF"><link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon.png"><link rel="icon" type="image/ico" sizes="32x32" href="/images/favicon.ico"><meta http-equiv="Cache-Control" content="no-transform"><meta http-equiv="Cache-Control" content="no-siteapp"><link rel="alternate" type="application/rss+xml" title="永不停歇" href="https://zrn-code.github.io/rss.xml"><link rel="alternate" type="application/atom+xml" title="永不停歇" href="https://zrn-code.github.io/atom.xml"><link rel="alternate" type="application/json" title="永不停歇" href="https://zrn-code.github.io/feed.json"><script src="//code.tidio.co/xwpoo3nkpkhs9n7qnbgoxgfroyidjvjl.js" async></script><script type="text/javascript" src="https://cdn.jsdelivr.net/npm/artitalk"></script><link rel="stylesheet" href="//fonts.googleapis.com/css?family=Mulish:300,300italic,400,400italic,700,700italic%7CFredericka%20the%20Great:300,300italic,400,400italic,700,700italic%7CNoto%20Serif%20JP:300,300italic,400,400italic,700,700italic%7CNoto%20Serif%20SC:300,300italic,400,400italic,700,700italic%7CInconsolata:300,300italic,400,400italic,700,700italic&display=swap&subset=latin,latin-ext"><link rel="stylesheet" href="/css/app.css?v=0.2.5"><link rel="canonical" href="https://zrn-code.github.io/page/3/"><title>Zrn Code = 永不停歇 = 學習歷程</title><meta name="generator" content="Hexo 5.2.0"></head><body itemscope itemtype="http://schema.org/WebPage"><div id="loading"><div class="cat"><div class="body"></div><div class="head"><div class="face"></div></div><div class="foot"><div class="tummy-end"></div><div class="bottom"></div><div class="legs left"></div><div class="legs right"></div></div><div class="paw"><div class="hands left"></div><div class="hands right"></div></div></div></div><div id="container"><header id="header" itemscope itemtype="http://schema.org/WPHeader"><div class="inner"><div id="brand"><div class="pjax"><a href="/" class="logo" rel="start"><p class="artboard">Zrn Code</p><h1 itemprop="name headline" class="title">永不停歇</h1></a><p class="meta" itemprop="description">= 學習歷程 =</p></div></div><nav id="nav"><div class="inner"><div class="toggle"><div class="lines" aria-label="切換導航欄"><span class="line"></span> <span class="line"></span> <span class="line"></span></div></div><ul class="menu"><li class="item title"><a href="/" rel="start">Zrn Code</a></li></ul><ul class="right"><li class="item theme"><i class="ic i-sun"></i></li><li class="item search"><i class="ic i-search"></i></li></ul></div></nav></div><div id="imgs" class="pjax"><ul><li class="item" data-background-image="https://tva2.sinaimg.cn/large/006q0MNVgy1h2b2037upjj32yo1o0txc.jpg"></li><li class="item" data-background-image="https://tva2.sinaimg.cn/large/006q0MNVgy1gyquyv2hesj315o0ngtd5.jpg"></li><li class="item" data-background-image="https://tva2.sinaimg.cn/large/6833939bly1giclfb3vzhj20zk0m8wny.jpg"></li><li class="item" data-background-image="https://tva2.sinaimg.cn/large/006q0MNVgy1gywn2vmdypj315o0r3al9.jpg"></li><li class="item" data-background-image="https://tva2.sinaimg.cn/large/006q0MNVgy1gyquz33x0gj315o0ng11k.jpg"></li><li class="item" data-background-image="https://tva2.sinaimg.cn/large/6833939bly1giclxp31goj20zk0m8qv5.jpg"></li></ul></div><div id="waves"><svg class="waves" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" viewBox="0 24 150 28" preserveAspectRatio="none" shape-rendering="auto"><defs><path id="gentle-wave" d="M-160 44c30 0 58-18 88-18s 58 18 88 18 58-18 88-18 58 18 88 18 v44h-352z"/></defs><g class="parallax"><use xlink:href="#gentle-wave" x="48" y="0"/><use xlink:href="#gentle-wave" x="48" y="3"/><use xlink:href="#gentle-wave" x="48" y="5"/><use xlink:href="#gentle-wave" x="48" y="7"/></g></svg></div></header><main><div class="inner"><div id="main" class="pjax"><div class="index wrap"><div class="segments posts"><article class="item"><div class="cover"><a href="/2021/09/27/lin-ML-12/" itemprop="url" title="第12篇、Nonlinear Transformation"><img data-src="https://tva2.sinaimg.cn/mw690/6833939bly1gicm07ih54j20zk0m84qp.jpg"></a></div><div class="info"><div class="meta"><span class="item" title="創建時間：2021-09-27 10:21:25"><span class="icon"><i class="ic i-calendar"></i> </span><time itemprop="dateCreated datePublished" datetime="2021-09-27T10:21:25+08:00">2021-09-27</time> </span><span class="item" title="文章字數"><span class="icon"><i class="ic i-pen"></i> </span><span>4.9k</span> <span class="text">字</span> </span><span class="item" title="所需閱讀時間"><span class="icon"><i class="ic i-clock"></i> </span><span>4 分鐘</span></span></div><h3><a href="/2021/09/27/lin-ML-12/" itemprop="url" title="第12篇、Nonlinear Transformation">第12篇、Nonlinear Transformation</a></h3><div class="excerpt">上一節課，我們介紹了分類問題的三種線性模型，可以用來解決 binary classification 和 multiclass classification 問題。本節課主要介紹非線性的模型來解決分類問題。 # Quadratic Hypothesis 之前介紹的線性模型，在 2D 平面上是一條直線，在 3D 空間中是一個平面。數學上，我們用線性得分函數 s 來表示：s=wTxs=w^Txs=wTx。其中，x 為特徵值向量，w 為權重，s 是線性的。 線性模型的優點就是，它的 VC Dimension 比較小，保證了Ein≈EoutE_{in}\approx...</div><div class="meta footer"><span><a href="/categories/learn/MachineBasic/" itemprop="url" title="林軒田機器學習基石課程學習筆記"><i class="ic i-flag"></i>林軒田機器學習基石課程學習筆記</a></span></div><a href="/2021/09/27/lin-ML-12/" itemprop="url" title="第12篇、Nonlinear Transformation" class="btn">more...</a></div></article><article class="item"><div class="cover"><a href="/2021/09/25/linear-algebra-01/" itemprop="url" title="第01篇、概念簡介"><img data-src="https://tva2.sinaimg.cn/mw690/006q0MNVgy1gyquz0sf8wj315o0o7jy9.jpg"></a></div><div class="info"><div class="meta"><span class="item" title="創建時間：2021-09-25 14:33:52"><span class="icon"><i class="ic i-calendar"></i> </span><time itemprop="dateCreated datePublished" datetime="2021-09-25T14:33:52+08:00">2021-09-25</time> </span><span class="item" title="文章字數"><span class="icon"><i class="ic i-pen"></i> </span><span>6k</span> <span class="text">字</span> </span><span class="item" title="所需閱讀時間"><span class="icon"><i class="ic i-clock"></i> </span><span>5 分鐘</span></span></div><h3><a href="/2021/09/25/linear-algebra-01/" itemprop="url" title="第01篇、概念簡介">第01篇、概念簡介</a></h3><div class="excerpt">什麼是線性代數？ 研究具有線性特質的代數結構 e.g. 方程組的解集合 # 線性特質 linear # 線性函數 滿足以下條件的函數fff 稱作為線性函數 {f(x+y)=f(x)+f(y)∀x,yf(cx)=cf(x)∀c∈R∀x \left\{ \begin{array}{cl} f(x+y) &amp;amp; = f(x)+f(y) &amp;amp;\forall x,y\\ f(cx) &amp;amp; = cf(x)&amp;amp;\forall c\in \mathbb{R}&amp;amp;\forall x \end{array}...</div><div class="meta footer"><span><a href="/categories/senior/%E7%B7%9A%E6%80%A7%E4%BB%A3%E6%95%B8/" itemprop="url" title="線性代數"><i class="ic i-flag"></i>線性代數</a></span></div><a href="/2021/09/25/linear-algebra-01/" itemprop="url" title="第01篇、概念簡介" class="btn">more...</a></div></article><article class="item"><div class="cover"><a href="/2021/09/20/lin-ML-11/" itemprop="url" title="第11篇、Linear Models for Classification"><img data-src="https://tva2.sinaimg.cn/mw690/006q0MNVgy1gyquz3verjj315o0ngwok.jpg"></a></div><div class="info"><div class="meta"><span class="item" title="創建時間：2021-09-20 10:21:21"><span class="icon"><i class="ic i-calendar"></i> </span><time itemprop="dateCreated datePublished" datetime="2021-09-20T10:21:21+08:00">2021-09-20</time> </span><span class="item" title="文章字數"><span class="icon"><i class="ic i-pen"></i> </span><span>5.8k</span> <span class="text">字</span> </span><span class="item" title="所需閱讀時間"><span class="icon"><i class="ic i-clock"></i> </span><span>5 分鐘</span></span></div><h3><a href="/2021/09/20/lin-ML-11/" itemprop="url" title="第11篇、Linear Models for Classification">第11篇、Linear Models for Classification</a></h3><div class="excerpt">上一節課，我們介紹了 Logistic Regression 問題，建立 cross-entropy error，並提出使用梯度下降演算法 gradient descent 來獲得最好的 logistic hypothesis。本節課繼續介紹使用線性模型來解決分類問題。 # Linear Models for Binary Classification 之前介紹幾種線性模型都有一個共同點，就是都有樣本特徵 x 的加權運算，我們引入一個線性得分函數 s: s=wTxs=w^Txs=wTx 的三種線性模型。 第一種是 linear classification 。線性分類模型的...</div><div class="meta footer"><span><a href="/categories/learn/MachineBasic/" itemprop="url" title="林軒田機器學習基石課程學習筆記"><i class="ic i-flag"></i>林軒田機器學習基石課程學習筆記</a></span></div><a href="/2021/09/20/lin-ML-11/" itemprop="url" title="第11篇、Linear Models for Classification" class="btn">more...</a></div></article><article class="item"><div class="cover"><a href="/2021/09/16/lin-ML-10/" itemprop="url" title="第10篇、Logistic Regression"><img data-src="https://tva2.sinaimg.cn/mw690/006q0MNVgy1gyquz3qsowj315o0ngdq7.jpg"></a></div><div class="info"><div class="meta"><span class="item" title="創建時間：2021-09-16 19:09:56"><span class="icon"><i class="ic i-calendar"></i> </span><time itemprop="dateCreated datePublished" datetime="2021-09-16T19:09:56+08:00">2021-09-16</time> </span><span class="item" title="文章字數"><span class="icon"><i class="ic i-pen"></i> </span><span>4.6k</span> <span class="text">字</span> </span><span class="item" title="所需閱讀時間"><span class="icon"><i class="ic i-clock"></i> </span><span>4 分鐘</span></span></div><h3><a href="/2021/09/16/lin-ML-10/" itemprop="url" title="第10篇、Logistic Regression">第10篇、Logistic Regression</a></h3><div class="excerpt">上一節課，介紹了 Linear Regression 線性回歸，以及用平方錯誤來尋找最佳的權重向量www，獲得最好的線性預測。本節課將介紹 Logistic Regression 邏輯回歸問題。 # Logistic Regression Problem 一個心臟病預測的問題：根據患者的年齡、血壓、體重等資訊，來預測患者是否會有心臟病。很明顯這是一個二分類問題，其輸出 y 只有 {-1,1} 兩種情況。 二元分類在一般情況下，理想的目標函數 f (x)&amp;gt;0.5，則判斷為正類 1；若 f (x)&amp;lt;0.5，則判斷為負類 -...</div><div class="meta footer"><span><a href="/categories/learn/MachineBasic/" itemprop="url" title="林軒田機器學習基石課程學習筆記"><i class="ic i-flag"></i>林軒田機器學習基石課程學習筆記</a></span></div><a href="/2021/09/16/lin-ML-10/" itemprop="url" title="第10篇、Logistic Regression" class="btn">more...</a></div></article><article class="item"><div class="cover"><a href="/2021/09/11/lin-ML-09/" itemprop="url" title="第09篇、Linear Regression"><img data-src="https://tva2.sinaimg.cn/mw690/6833939bly1gicitht3xtj20zk0m8k5v.jpg"></a></div><div class="info"><div class="meta"><span class="item" title="創建時間：2021-09-11 19:29:17"><span class="icon"><i class="ic i-calendar"></i> </span><time itemprop="dateCreated datePublished" datetime="2021-09-11T19:29:17+08:00">2021-09-11</time> </span><span class="item" title="文章字數"><span class="icon"><i class="ic i-pen"></i> </span><span>3.6k</span> <span class="text">字</span> </span><span class="item" title="所需閱讀時間"><span class="icon"><i class="ic i-clock"></i> </span><span>3 分鐘</span></span></div><h3><a href="/2021/09/11/lin-ML-09/" itemprop="url" title="第09篇、Linear Regression">第09篇、Linear Regression</a></h3><div class="excerpt"># Linear Regression Problem 在之前的 Linear Classification 課程中，講了信用卡發放的例子，利用機器學習來決定是否給用戶發放信用卡。本節課仍然引入信用卡的例子，來解決給用戶發放信用卡額度的問題，這就是一個線性回歸（ Linear Regression ）問題。 令用戶特徵集為 d 維的XXX，加上常數項，維度為d+1d+1d+1，與權重 w 的線性組合即為 Hypothesis ,...</div><div class="meta footer"><span><a href="/categories/learn/MachineBasic/" itemprop="url" title="林軒田機器學習基石課程學習筆記"><i class="ic i-flag"></i>林軒田機器學習基石課程學習筆記</a></span></div><a href="/2021/09/11/lin-ML-09/" itemprop="url" title="第09篇、Linear Regression" class="btn">more...</a></div></article><article class="item"><div class="cover"><a href="/2021/09/03/lin-ML-08/" itemprop="url" title="第08篇、Noise and Error"><img data-src="https://tva2.sinaimg.cn/mw690/6833939bly1gipeyvx1d4j20zk0m8hdt.jpg"></a></div><div class="info"><div class="meta"><span class="item" title="創建時間：2021-09-03 22:32:09"><span class="icon"><i class="ic i-calendar"></i> </span><time itemprop="dateCreated datePublished" datetime="2021-09-03T22:32:09+08:00">2021-09-03</time> </span><span class="item" title="文章字數"><span class="icon"><i class="ic i-pen"></i> </span><span>2.3k</span> <span class="text">字</span> </span><span class="item" title="所需閱讀時間"><span class="icon"><i class="ic i-clock"></i> </span><span>2 分鐘</span></span></div><h3><a href="/2021/09/03/lin-ML-08/" itemprop="url" title="第08篇、Noise and Error">第08篇、Noise and Error</a></h3><div class="excerpt"># Noise and Probablistic target 上節課推導 VC Dimension 的資料集是在沒有 Noise 的情況下， 本節課討論如果資料集本身存在 Noise ，那 VC Dimension 的推導是否還成立呢？ 首先， Data Sets 的 Noise 一般有三種情況： 由於人為因素，正類被誤分為負類，或者負類被誤分為正類； 同樣特徵的樣本被模型分為不同的類； 樣本的特徵被錯誤記錄和使用。 之前的資料集是確定的，即沒有 Noise 的，我們稱之為 Deterministic 。現在有 Noise 了，也就是說在某點處不再是確定分佈，而是概率分佈了，即對每個...</div><div class="meta footer"><span><a href="/categories/learn/MachineBasic/" itemprop="url" title="林軒田機器學習基石課程學習筆記"><i class="ic i-flag"></i>林軒田機器學習基石課程學習筆記</a></span></div><a href="/2021/09/03/lin-ML-08/" itemprop="url" title="第08篇、Noise and Error" class="btn">more...</a></div></article><article class="item"><div class="cover"><a href="/2021/08/31/lin-ML-07/" itemprop="url" title="第07篇、The VC Dimension"><img data-src="https://tva2.sinaimg.cn/mw690/6833939bly1giciundwu5j20zk0m8n9e.jpg"></a></div><div class="info"><div class="meta"><span class="item" title="創建時間：2021-08-31 20:11:26"><span class="icon"><i class="ic i-calendar"></i> </span><time itemprop="dateCreated datePublished" datetime="2021-08-31T20:11:26+08:00">2021-08-31</time> </span><span class="item" title="文章字數"><span class="icon"><i class="ic i-pen"></i> </span><span>3.4k</span> <span class="text">字</span> </span><span class="item" title="所需閱讀時間"><span class="icon"><i class="ic i-clock"></i> </span><span>3 分鐘</span></span></div><h3><a href="/2021/08/31/lin-ML-07/" itemprop="url" title="第07篇、The VC Dimension">第07篇、The VC Dimension</a></h3><div class="excerpt"># Definition of VC Dimension 首先，我們知道如果一個假設空間 H 有 break point k ，那麼它的成長函數是有界的，它的上界稱為 Bound function 。 根據數學歸納法， Bound function 也是有界的，且上界為Nk−1N^{k-1}Nk−1。從下面的表格可以看出，N(k−1)N(k-1)N(k−1) 比B(N,k)B(N,k)B(N,k) 鬆弛很多。 則根據上一節課的推導，VC bound 就可以轉換為： 這樣，不等式只與 k 和 N 相關了，一般情況下樣本 N 足夠大，所以我們只考慮 k 值。有如下結論： 若假設空間 H 有...</div><div class="meta footer"><span><a href="/categories/learn/MachineBasic/" itemprop="url" title="林軒田機器學習基石課程學習筆記"><i class="ic i-flag"></i>林軒田機器學習基石課程學習筆記</a></span></div><a href="/2021/08/31/lin-ML-07/" itemprop="url" title="第07篇、The VC Dimension" class="btn">more...</a></div></article><article class="item"><div class="cover"><a href="/2021/07/26/lin-ML-06/" itemprop="url" title="第06篇、Theory of Generalization"><img data-src="https://tva2.sinaimg.cn/mw690/006q0MNVgy1gyquz1f3bzj315o0irqa1.jpg"></a></div><div class="info"><div class="meta"><span class="item" title="創建時間：2021-07-26 15:56:33"><span class="icon"><i class="ic i-calendar"></i> </span><time itemprop="dateCreated datePublished" datetime="2021-07-26T15:56:33+08:00">2021-07-26</time> </span><span class="item" title="文章字數"><span class="icon"><i class="ic i-pen"></i> </span><span>2.9k</span> <span class="text">字</span> </span><span class="item" title="所需閱讀時間"><span class="icon"><i class="ic i-clock"></i> </span><span>3 分鐘</span></span></div><h3><a href="/2021/07/26/lin-ML-06/" itemprop="url" title="第06篇、Theory of Generalization">第06篇、Theory of Generalization</a></h3><div class="excerpt">上一節課，我們主要探討了當 M 的數值大小對機器學習的影響。如果 M 很大，那麼就不能保證機器學習有很好的泛化能力，所以問題轉換為驗證 M 有限，即最好是按照多項式成長。然後通過引入了成長函數mH(N)m_H(N)mH​(N) 和 dichotomy 以及 break point 的概念，提出 2D perceptrons 的成長函數mH(N)m_H(N)mH​(N) 是多項式級別的猜想。這就是本節課將要深入探討和證明的內容。 # Restriction of Break Point 我們先回顧一下上節課的內容，四種成長函數與 break point 的關係： 下面引入一個例子，如果...</div><div class="meta footer"><span><a href="/categories/learn/MachineBasic/" itemprop="url" title="林軒田機器學習基石課程學習筆記"><i class="ic i-flag"></i>林軒田機器學習基石課程學習筆記</a></span></div><a href="/2021/07/26/lin-ML-06/" itemprop="url" title="第06篇、Theory of Generalization" class="btn">more...</a></div></article><article class="item"><div class="cover"><a href="/2021/07/19/lin-ML-05/" itemprop="url" title="第05篇、 Training versus Testing"><img data-src="https://tva2.sinaimg.cn/mw690/6833939bly1gipew28b65j20zk0m8hdt.jpg"></a></div><div class="info"><div class="meta"><span class="item" title="創建時間：2021-07-19 14:14:30"><span class="icon"><i class="ic i-calendar"></i> </span><time itemprop="dateCreated datePublished" datetime="2021-07-19T14:14:30+08:00">2021-07-19</time> </span><span class="item" title="文章字數"><span class="icon"><i class="ic i-pen"></i> </span><span>4k</span> <span class="text">字</span> </span><span class="item" title="所需閱讀時間"><span class="icon"><i class="ic i-clock"></i> </span><span>4 分鐘</span></span></div><h3><a href="/2021/07/19/lin-ML-05/" itemprop="url" title="第05篇、 Training versus Testing">第05篇、 Training versus Testing</a></h3><div class="excerpt">上節課，主要介紹了機器學習的可行性。首先，由 NFL 定理可知，機器學習貌似是不可行的。但是，隨後引入了統計學知識，如果樣本資料足夠大，且 hypothesis 個數有限，那麼機器學習一般就是可行的。本節課將討論機器學習的核心問題，嚴格證明為什麼機器可以學習。 從上節課最後的問題出發，即當 hypothesis 的個數是無限多的時候，機器學習的可行性是否仍然成立？ # Recap and Preview 我們先來看一下基於統計學的機器學習流程圖： 該流程圖中，訓練樣本 D 和最終測試 h 的樣本都是來自同一個資料分佈，這是機器能夠學習的前提。 另外，訓練樣本 D 應該足夠大，且...</div><div class="meta footer"><span><a href="/categories/learn/MachineBasic/" itemprop="url" title="林軒田機器學習基石課程學習筆記"><i class="ic i-flag"></i>林軒田機器學習基石課程學習筆記</a></span></div><a href="/2021/07/19/lin-ML-05/" itemprop="url" title="第05篇、 Training versus Testing" class="btn">more...</a></div></article><article class="item"><div class="cover"><a href="/2021/07/01/story03/" itemprop="url" title="誰都不傻，只是不說而已"><img data-src="https://tva2.sinaimg.cn/mw690/6833939bly1gipet4bz0yj20zk0m8e81.jpg"></a></div><div class="info"><div class="meta"><span class="item" title="創建時間：2021-07-01 09:03:23"><span class="icon"><i class="ic i-calendar"></i> </span><time itemprop="dateCreated datePublished" datetime="2021-07-01T09:03:23+08:00">2021-07-01</time> </span><span class="item" title="文章字數"><span class="icon"><i class="ic i-pen"></i> </span><span>1.8k</span> <span class="text">字</span> </span><span class="item" title="所需閱讀時間"><span class="icon"><i class="ic i-clock"></i> </span><span>2 分鐘</span></span></div><h3><a href="/2021/07/01/story03/" itemprop="url" title="誰都不傻，只是不說而已">誰都不傻，只是不說而已</a></h3><div class="excerpt">以前，我很傻。對所有人都竭盡心力的付出，卻換不來別人半分的理解和珍惜。現在，我裝傻。選擇看穿不說穿，看透不說透，別人怎麼對我，我就怎麼對別人，因為時間久了，我才漸漸明白誰是真心對我的人，誰才是值得我對他好的人。 以前的我總是不顧一切的對別人好，卻不曾想自己為傻傻地付出別人根本就不當一回事。方知這世上最薄不過感情，最涼不過人心，很多時候對別人越好，對方不但不會感激你，反而還會得寸進尺。 不經想起曾經看過的一篇新聞，有一家饅頭店，老闆看到很多工人與流浪漢經常吃不上熱飯，便決定辦一個免費送饅頭的活動。領愛心饅頭的人絡繹不絕，剛開始饅頭店面為每個人準備了五個饅頭，但是堅持了十多天之後，工作量太大，身體...</div><div class="meta footer"><span><a href="/categories/life/" itemprop="url" title="生活點滴 &amp; 情感抒發"><i class="ic i-flag"></i>生活點滴 & 情感抒發</a></span></div><a href="/2021/07/01/story03/" itemprop="url" title="誰都不傻，只是不說而已" class="btn">more...</a></div></article></div></div><nav class="pagination"><div class="inner"><a class="extend prev" rel="prev" href="/page/2/"><i class="ic i-angle-left" aria-label="上一頁"></i></a><a class="page-number" href="/">1</a><a class="page-number" href="/page/2/">2</a><span class="page-number current">3</span><a class="page-number" href="/page/4/">4</a><span class="space">&hellip;</span><a class="page-number" href="/page/40/">40</a><a class="extend next" rel="next" href="/page/4/"><i class="ic i-angle-right" aria-label="下一頁"></i></a></div></nav></div><div id="sidebar"><div class="inner"><div class="panels"><div class="inner"><div class="contents panel pjax" data-title="文章目錄"></div><div class="related panel pjax" data-title="系列文章"></div><div class="overview panel" data-title="本站概要"><div class="author" itemprop="author" itemscope itemtype="http://schema.org/Person"><img class="image" itemprop="image" alt="Zrn（*゜ー゜*）" data-src="/images/avatar.jpg"><p class="name" itemprop="name">Zrn（*゜ー゜*）</p><div class="description" itemprop="description">再苦再累也要堅強，只為那些期待眼神</div></div><nav class="state"><div class="item posts"><a href="/archives/"><span class="count">400</span> <span class="name">文章</span></a></div><div class="item categories"><a href="/categories/"><span class="count">23</span> <span class="name">分類</span></a></div><div class="item tags"><a href="/tags/"><span class="count">127</span> <span class="name">標籤</span></a></div></nav><div class="social"><span class="exturl item github" data-url="aHR0cHM6Ly9naXRodWIuY29tL3pybi1jb2Rl" title="https:&#x2F;&#x2F;github.com&#x2F;zrn-code"><i class="ic i-github"></i></span> <span class="exturl item email" data-url="bWFpbHRvOnp4YzA5Nzg4Mjc5MDlAbWFpbC5jb20=" title="mailto:zxc0978827909@mail.com"><i class="ic i-envelope"></i></span></div><ul class="menu"><li class="item"><a href="/" rel="section"><i class="ic i-home"></i>首頁</a></li><li class="item dropdown"><a href="javascript:void(0);"><i class="ic i-user"></i>關於</a><ul class="submenu"><li class="item"><a href="/about/" rel="section"><i class="ic i-user"></i>關於作者</a></li><li class="item"><a href="/about-website/" rel="section"><i class="ic i-chrome"></i>關於網站</a></li></ul></li><li class="item dropdown"><a href="javascript:void(0);"><i class="ic i-feather"></i>文章</a><ul class="submenu"><li class="item"><a href="/archives/" rel="section"><i class="ic i-list-alt"></i>歸檔</a></li><li class="item"><a href="/categories/" rel="section"><i class="ic i-th"></i>分類</a></li><li class="item"><a href="/tags/" rel="section"><i class="ic i-tags"></i>標籤</a></li></ul></li><li class="item dropdown"><a href="javascript:void(0);"><i class="ic i-magic"></i>神奇連結</a><ul class="submenu"><li class="item"><a href="/friends/" rel="section"><i class="ic i-heart"></i>小夥伴</a></li><li class="item"><a href="/links/" rel="section"><i class="ic i-opera"></i>推薦網站</a></li></ul></li><li class="item dropdown"><a href="javascript:void(0);"><i class="ic i-star"></i>生活紀錄</a><ul class="submenu"><li class="item"><a href="/gallery" rel="section"><i class="ic i-heart"></i>圖片收藏</a></li><li class="item"><a href="/talking/" rel="section"><i class="ic i-pen"></i>輕鬆隨筆</a></li></ul></li><li class="item"><a href="/statistics/" rel="section"><i class="ic i-clock"></i>文章統計</a></li></ul></div></div></div><ul id="quick"><li class="prev pjax"><a href="/page/2/" rel="prev" title="上一篇"><i class="ic i-chevron-left"></i></a></li><li class="up"><i class="ic i-arrow-up"></i></li><li class="down"><i class="ic i-arrow-down"></i></li><li class="next pjax"><a href="/page/4/" rel="next" title="下一篇"><i class="ic i-chevron-right"></i></a></li><li class="percent"></li></ul></div></div><div class="dimmer"></div></div></main><footer id="footer"><div class="inner"><div class="widgets"></div><div class="status"><div class="copyright">&copy; 2020 – <span itemprop="copyrightYear">2022</span> <span class="with-love"><i class="ic i-sakura rotate"></i> </span><span class="author" itemprop="copyrightHolder">Zrn（*゜ー゜*） @ Zrn Code</span></div><div class="count"><span class="post-meta-item-icon"><i class="ic i-chart-area"></i> </span><span title="總字數">595k 字</span> <span class="post-meta-divider">|</span> <span class="post-meta-item-icon"><i class="ic i-coffee"></i> </span><span title="所需總閱讀時間">9:01</span></div></div></div></footer></div><script data-config type="text/javascript">var LOCAL={path:"page/3/",favicon:{show:"復活成功（●´3｀●）",hide:"瀏覽器崩潰啦(´Д｀)"},search:{placeholder:"文章搜尋",empty:"關於 「 ${query} 」 ，什麼也沒搜到",stats:"${time} ms 內找到 ${hits} 條結果"},valine:!0,fancybox:!0,copyright:'複製成功，轉載請遵守 <i class="ic i-creative-commons"></i>BY-NC-SA 協議。',ignores:[function(e){return e.includes("#")},function(e){return new RegExp(LOCAL.path+"$").test(e)}]}</script><script src="https://cdn.polyfill.io/v2/polyfill.js"></script><script src="//cdn.jsdelivr.net/combine/npm/pace-js@1.0.2/pace.min.js,npm/pjax@0.2.8/pjax.min.js,npm/whatwg-fetch@3.4.0/dist/fetch.umd.min.js,npm/animejs@3.2.0/lib/anime.min.js,npm/algoliasearch@4/dist/algoliasearch-lite.umd.js,npm/instantsearch.js@4/dist/instantsearch.production.min.js,npm/lozad@1/dist/lozad.min.js,npm/quicklink@2/dist/quicklink.umd.js,npm/echarts@5.2.2/dist/echarts.min.js"></script><script src="/js/app.js?v=0.2.5"></script></body></html><!-- rebuild by hrmmi -->